# 33. CAP теорема. Пример

`def` **CAP теорема** гласит, что в распределённой информационной системы возможно обеспечить не более двух из перечисленных свойств _(Consistency, Availability, Partition tolerance)_

![CAP-треугольник](../../../images/cap-theorem.png)

## Целостность

- Во всех узлах в один момент времени данные не противоречат друг другу

- Два запроса в один момент времени к двум разным узлам, то результат выполнения обоих откликов будет одинаков

:::tip
Одинаковые результаты с любого узла в один момент времени
:::

## Доступность

- Любой запрос к распределённой системе завершается корректным откликом в пределах заданного интервала времени, однако без гарантии, что отклики от всех узлов совпадут

## Устойчивость к распределению

- Расщепление распределённой системы на несколько изолированных секций не приводит к некоррекности отклика от каждой из секций

:::tip
CAP - треугольник
:::

:::tip
Все реляционные БД - это `CA-системы`
:::

___

## Пример

### 1. Централизованная система

![Централизованная система](../../../images/central-system.png)

Является C системой, так как всего один источник правды — + Consistency.

### 2. Решение — нанять компаньона (нет взаимосвязи между обработчиками)

![А-система](../../../images/a-system.jpg)

Является A системой, так как при неисправности одного обработчика, может работать другой — +Availability.

Однако теряем Consistency, так как нету связи между источниками правды.

### 3. Принимаем решение о согласовании данных (Распределённая система с транзакционной репликацией данных)

![Транзакционная репликация](../../../images/transactional-replication.jpg)

Проблема доступности при недоступности хотя бы одного узла (пользователь ждёт пока я согласую ему запись, пока сам жду ответа от недоступного узла, так как он недоступен по каким-то причинам)

### 4. Распределение системы

  1. **Распределённая система с гарантированной репликацией данных**

      При звонке клиента пингуем второй узел на доступность. Если получем понг, то согласуем с ним данные, если нет, то кладём изменения в какую-то общую очереь и продолжаем работать.

      Когда узел поднимется, он первым делом из очереди прочитает изменения.

      Это CA система. Но нет Partition tolerance. Так как для соблюдения РТ нужен гарантированный канал связи. Если не пришёл отклик от узла, мы не знаем, это нет связи или узел действительно неактивен. Если положим в очередь, а на самом деле просто не было связи, когда связь восстановится, узел не будет знать о том, что в очереди что-то есть (так как он продолжал работать, просто связи не было). Таким образом получим некорректный отклик при разделении узлов.

  2. **Распределённая система с гарантированным откликом**

      Целостность данных в конечном счёте.
      AP система.

      После разговора с клиентом сразу рассылаю на все узлы в буфер данные, которые только что получил.

      Все узлы с какой-то переодичностью разбирают свои буферы.
      Тогда на длительном промежутке консистентность будет

  3. **Распределённая система с гарантированной целостностью данных**

      СР система.
      Невозможно обеспечить полную доступность.

      Блокируем запросы клиентов, если не удаётся подтведрдить статус узла.

